{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:25:12.160881Z",
     "start_time": "2024-04-02T06:25:12.137229Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from underthesea import word_tokenize\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from typing import Iterable, List\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                             English  \\\n0  rachel pike : the science behind a climate hea...   \n1  in 4 minutes , atmospheric chemist rachel pike...   \n2  i &apos;d like to talk to you today about the ...   \n3  headlines that look like this when they have t...   \n4  they are both two branches of the same field o...   \n\n                                          Vietnamese  \n0         khoa học đằng sau một tiêu đề về khí hậu\\n  \n1  trong 4 phút , chuyên gia hoá học khí quyển ra...  \n2  tôi muốn cho các bạn biết về sự to lớn của nhữ...  \n3  có những dòng trông như thế này khi bàn về biế...  \n4  cả hai đều là một nhánh của cùng một lĩnh vực ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Vietnamese</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rachel pike : the science behind a climate hea...</td>\n      <td>khoa học đằng sau một tiêu đề về khí hậu\\n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>in 4 minutes , atmospheric chemist rachel pike...</td>\n      <td>trong 4 phút , chuyên gia hoá học khí quyển ra...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i &amp;apos;d like to talk to you today about the ...</td>\n      <td>tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>headlines that look like this when they have t...</td>\n      <td>có những dòng trông như thế này khi bàn về biế...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>they are both two branches of the same field o...</td>\n      <td>cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train/eng-vie.csv')\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:54:02.214834Z",
     "start_time": "2024-04-02T04:54:00.812964Z"
    }
   },
   "id": "6a13bd5fc543b6da",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-2c91c9a3b01aafa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-2c91c9a3b01aafa\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/Mar26_06-13-08_7ff693238ec8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T06:25:23.614298Z",
     "start_time": "2024-04-02T06:25:16.266740Z"
    }
   },
   "id": "65d3276376ebb34d",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "SRC_LANGUAGE = 'English'\n",
    "TGT_LANGUAGE = 'Vietnamese'\n",
    "\n",
    "def vi_tokenizer(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return tokens\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('basic_english')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer(vi_tokenizer)\n",
    "\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    for index,data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language])\n",
    "\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "# Load tokenizer và vocab từ file\n",
    "with open('models/token_vocab_data.pkl', 'rb') as f:\n",
    "    token_transform, vocab_transform = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:54:08.391139Z",
     "start_time": "2024-04-02T04:54:08.272372Z"
    }
   },
   "id": "209549ddbfab0ec",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocabulary size: 52051\n",
      "Vietnamese vocabulary size: 50359\n"
     ]
    }
   ],
   "source": [
    "for language in ['English', 'Vietnamese']:\n",
    "    print(f\"{language} vocabulary size: {len(vocab_transform[language])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:54:10.638261Z",
     "start_time": "2024-04-02T04:54:10.632167Z"
    }
   },
   "id": "467de82aa05041fa",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Check whether running on gpu or cpu\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float = 0.1,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:54:12.825018Z",
     "start_time": "2024-04-02T04:54:12.804087Z"
    }
   },
   "id": "6397f946969295ba",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:54:16.029018Z",
     "start_time": "2024-04-02T04:54:16.019495Z"
    }
   },
   "id": "33a45734643439b4",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(52051, 50359)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "\n",
    "SRC_VOCAB_SIZE, TGT_VOCAB_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-28T11:36:50.841341Z",
     "start_time": "2024-03-28T11:36:50.825700Z"
    }
   },
   "id": "80a74b2a85a9f3f5",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.manual_seed(22)\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8 # embed_dim must be divisible by num_heads\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 32\n",
    "NUM_ENCODER_LAYERS = 4\n",
    "NUM_DECODER_LAYERS = 4\n",
    "DROP_OUT = 0.1\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM,DROP_OUT)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:54:20.418386Z",
     "start_time": "2024-04-02T04:54:18.210234Z"
    }
   },
   "id": "3f6c8d7ba4255814",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and tgt language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:54:26.524833Z",
     "start_time": "2024-04-02T04:54:26.515200Z"
    }
   },
   "id": "2a41b06eb247854",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trạng thái của mô hình từ file\n",
    "state_dict = torch.load(\"models/viEn_transformer.pth\" ,map_location=torch.device('cpu'))\n",
    "\n",
    "# Khôi phục trạng thái của mô hình từ state_dict\n",
    "transformer.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:54:29.742365Z",
     "start_time": "2024-04-02T04:54:28.805100Z"
    }
   },
   "id": "ba5f3db394260128",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE).long()\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:54:33.408504Z",
     "start_time": "2024-04-02T04:54:33.398511Z"
    }
   },
   "id": "d5cb8c39c7f2be2a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: Hello, how are you?\n",
      "Predicted Vietnamese Translation:  xin chào làm bạn thế nào hạ sinh một chiếc bánh \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_sentence = input('Enter an English sentence: ')\n",
    "\n",
    "# Print input and actual translation\n",
    "print('Input English sentence:', input_sentence)\n",
    "\n",
    "# Call the translate function here with the input sentence\n",
    "predicted_translation = translate(transformer, input_sentence)\n",
    "\n",
    "# Print predicted translation\n",
    "print('Predicted Vietnamese Translation:', predicted_translation)\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T08:11:16.656273Z",
     "start_time": "2024-04-02T08:11:14.401967Z"
    }
   },
   "id": "f0bb91826fe1972",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tất nhiên, dưới đây là 20 câu tiếng Anh cùng với bản dịch tiếng Việt:\n",
    "\n",
    "1. Hello, how are you?\n",
    "Xin chào, bạn có khỏe không?\n",
    "\n",
    "2. I love reading books.\n",
    "Tôi yêu thích đọc sách.\n",
    "\n",
    "3. She plays the piano beautifully.\n",
    "Cô ấy chơi piano đẹp đấy.\n",
    "\n",
    "4. Have you finished your homework yet?\n",
    "Bạn đã hoàn thành bài tập về nhà chưa?\n",
    "\n",
    "5. We are going to the beach tomorrow.\n",
    "Chúng tôi sẽ đi biển vào ngày mai.\n",
    "\n",
    "6. The cat is sleeping on the couch.\n",
    "Con mèo đang ngủ trên ghế sofa.\n",
    "\n",
    "7. He wants to learn how to cook.\n",
    "Anh ấy muốn học cách nấu ăn.\n",
    "\n",
    "8. My favorite color is blue.\n",
    "Màu yêu thích của tôi là màu xanh.\n",
    "\n",
    "9. They live in a big house near the park.\n",
    "Họ sống trong một căn nhà lớn gần công viên.\n",
    "\n",
    "10. Did you watch the new movie last night?\n",
    "Bạn đã xem bộ phim mới vào tối qua chưa?\n",
    "\n",
    "11. I can speak English and French.\n",
    "Tôi có thể nói tiếng Anh và tiếng Pháp.\n",
    "\n",
    "12. She's studying hard for her exams.\n",
    "Cô ấy đang học hành chăm chỉ cho kì thi.\n",
    "\n",
    "13. We went shopping at the mall yesterday.\n",
    "Chúng tôi đã đi mua sắm tại trung tâm thương mại vào ngày hôm qua.\n",
    "\n",
    "14. The weather is beautiful today, isn't it?\n",
    "Thời tiết hôm nay đẹp quá, phải không?\n",
    "\n",
    "15. He's always late for meetings.\n",
    "Anh ấy luôn đến muộn trong các cuộc họp.\n",
    "\n",
    "16. Can you help me with this math problem?\n",
    "Bạn có thể giúp tôi với bài toán này được không?\n",
    "\n",
    "17. We had a delicious dinner at the restaurant.\n",
    "Chúng tôi đã có một bữa tối ngon tại nhà hàng.\n",
    "\n",
    "18. She's a talented singer and dancer.\n",
    "Cô ấy là một ca sĩ và vũ công tài năng.\n",
    "\n",
    "19. My parents are coming to visit us next week.\n",
    "Bố mẹ tôi sẽ đến thăm chúng tôi vào tuần sau.\n",
    "\n",
    "20. I'm looking forward to the weekend.\n",
    "Tôi đang mong chờ cuối tuần đấy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3b2feffe6cb2d87"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0        English words/sentences\n89555       89555  I don't remember that at all.\n89556       89556  I don't remember that at all.\n89557       89557  I don't see anything special.\n89558       89558  I don't see anything strange.\n89559       89559  I don't see anything strange.\n89560       89560  I don't see how I can refuse.\n89561       89561  I don't take orders from you.\n89562       89562  I don't take orders from you.\n89563       89563  I don't talk to them anymore.\n89564       89564  I don't think I can eat this.",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>English words/sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>89555</th>\n      <td>89555</td>\n      <td>I don't remember that at all.</td>\n    </tr>\n    <tr>\n      <th>89556</th>\n      <td>89556</td>\n      <td>I don't remember that at all.</td>\n    </tr>\n    <tr>\n      <th>89557</th>\n      <td>89557</td>\n      <td>I don't see anything special.</td>\n    </tr>\n    <tr>\n      <th>89558</th>\n      <td>89558</td>\n      <td>I don't see anything strange.</td>\n    </tr>\n    <tr>\n      <th>89559</th>\n      <td>89559</td>\n      <td>I don't see anything strange.</td>\n    </tr>\n    <tr>\n      <th>89560</th>\n      <td>89560</td>\n      <td>I don't see how I can refuse.</td>\n    </tr>\n    <tr>\n      <th>89561</th>\n      <td>89561</td>\n      <td>I don't take orders from you.</td>\n    </tr>\n    <tr>\n      <th>89562</th>\n      <td>89562</td>\n      <td>I don't take orders from you.</td>\n    </tr>\n    <tr>\n      <th>89563</th>\n      <td>89563</td>\n      <td>I don't talk to them anymore.</td>\n    </tr>\n    <tr>\n      <th>89564</th>\n      <td>89564</td>\n      <td>I don't think I can eat this.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Giả sử df là DataFrame của bạn\n",
    "df = pd.read_csv('data/test/english_sentences.csv')\n",
    "df.iloc[89555:89565]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T04:55:30.438208Z",
     "start_time": "2024-04-02T04:55:30.265137Z"
    }
   },
   "id": "8415b4a4f8fc6074",
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
