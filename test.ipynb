{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-22T09:41:17.386056Z",
     "start_time": "2024-03-22T09:41:07.300939Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,string\n",
    "from underthesea import word_tokenize\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import Iterable, List\n",
    "from gensim.models import KeyedVectors\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from timeit import default_timer as timer\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                             English  \\\n0  rachel pike : the science behind a climate hea...   \n1  in 4 minutes , atmospheric chemist rachel pike...   \n2  i &apos;d like to talk to you today about the ...   \n3  headlines that look like this when they have t...   \n4  they are both two branches of the same field o...   \n\n                                          Vietnamese  \n0         khoa học đằng sau một tiêu đề về khí hậu\\n  \n1  trong 4 phút , chuyên gia hoá học khí quyển ra...  \n2  tôi muốn cho các bạn biết về sự to lớn của nhữ...  \n3  có những dòng trông như thế này khi bàn về biế...  \n4  cả hai đều là một nhánh của cùng một lĩnh vực ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Vietnamese</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rachel pike : the science behind a climate hea...</td>\n      <td>khoa học đằng sau một tiêu đề về khí hậu\\n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>in 4 minutes , atmospheric chemist rachel pike...</td>\n      <td>trong 4 phút , chuyên gia hoá học khí quyển ra...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>i &amp;apos;d like to talk to you today about the ...</td>\n      <td>tôi muốn cho các bạn biết về sự to lớn của nhữ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>headlines that look like this when they have t...</td>\n      <td>có những dòng trông như thế này khi bàn về biế...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>they are both two branches of the same field o...</td>\n      <td>cả hai đều là một nhánh của cùng một lĩnh vực ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/eng-vie.csv')\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:20:10.945202Z",
     "start_time": "2024-03-22T03:20:07.373802Z"
    }
   },
   "id": "6a13bd5fc543b6da",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "def vi_tokenizer(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return tokens\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('basic_english')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer(vi_tokenizer)\n",
    "\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    for index,data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language])\n",
    "\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "# Load tokenizer và vocab từ file\n",
    "with open('tokenizer_vocab.pkl', 'rb') as f:\n",
    "    token_transform, vocab_transform = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:25:41.197834Z",
     "start_time": "2024-03-22T03:25:40.976416Z"
    }
   },
   "id": "209549ddbfab0ec",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #Check whether running on gpu or cpu\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float = 0.1,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:21:41.317342Z",
     "start_time": "2024-03-22T03:21:41.288116Z"
    }
   },
   "id": "6397f946969295ba",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:21:51.508743Z",
     "start_time": "2024-03-22T03:21:51.495643Z"
    }
   },
   "id": "33a45734643439b4",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(52051, 50359)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC_LANGUAGE = 'English'\n",
    "TGT_LANGUAGE = 'Vietnamese'\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "\n",
    "SRC_VOCAB_SIZE, TGT_VOCAB_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:22:08.492686Z",
     "start_time": "2024-03-22T03:22:08.478402Z"
    }
   },
   "id": "80a74b2a85a9f3f5",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.manual_seed(22)\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8 # embed_dim must be divisible by num_heads\n",
    "FFN_HID_DIM = 256\n",
    "BATCH_SIZE = 32\n",
    "NUM_ENCODER_LAYERS = 4\n",
    "NUM_DECODER_LAYERS = 4\n",
    "DROP_OUT = 0.1\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM,DROP_OUT)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:22:23.573374Z",
     "start_time": "2024-03-22T03:22:21.968864Z"
    }
   },
   "id": "3f6c8d7ba4255814",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# src and tgt language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:23:52.389105Z",
     "start_time": "2024-03-22T03:23:52.363270Z"
    }
   },
   "id": "2a41b06eb247854",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trạng thái của mô hình từ file\n",
    "state_dict = torch.load(\"viEn_transformer.pth\" ,map_location=torch.device('cpu'))\n",
    "\n",
    "# Khôi phục trạng thái của mô hình từ state_dict\n",
    "transformer.load_state_dict(state_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:23:17.091836Z",
     "start_time": "2024-03-22T03:23:16.589877Z"
    }
   },
   "id": "ba5f3db394260128",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE).long()\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:23:55.613510Z",
     "start_time": "2024-03-22T03:23:55.593133Z"
    }
   },
   "id": "d5cb8c39c7f2be2a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: recommendation system for e ecommerce\n",
      "Predicted Vietnamese Translation:  hệ thống đề nghị cho hách dịch \n"
     ]
    }
   ],
   "source": [
    "input_sentence = input('Enter an English sentence: ')\n",
    "\n",
    "# Print input and actual translation\n",
    "print('Input English sentence:', input_sentence)\n",
    "\n",
    "# Call the translate function here with the input sentence\n",
    "predicted_translation = translate(transformer, input_sentence)\n",
    "\n",
    "# Print predicted translation\n",
    "print('Predicted Vietnamese Translation:', predicted_translation)\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T03:56:01.280759Z",
     "start_time": "2024-03-22T03:55:44.467802Z"
    }
   },
   "id": "f0bb91826fe1972",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Giả sử df là DataFrame của bạn\n",
    "df = pd.read_csv('data/eng-vie.csv')\n",
    "# Sử dụng hàm sample để lấy 10% dữ liệu\n",
    "sample_df = df.sample(frac=0.05, random_state=1)\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "sample_df.to_csv('small_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T09:44:56.721991Z",
     "start_time": "2024-03-22T09:44:54.997973Z"
    }
   },
   "id": "8415b4a4f8fc6074",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 English  \\\n0            you're not telling me anything i don't know   \n1      we need to get back to that sense of playfulne...   \n2                          how much is the entrance fee?   \n3          i can't play the piano at all. i'm all thumbs   \n4              you just looked at your clock , right ?\\n   \n...                                                  ...   \n19365  when you shake hands with somebody, you must l...   \n19366                            you were scared, right?   \n19367       it was uncertain whether he would marry her.   \n19368                   why would anyone else want this?   \n19369         all this is simple and easy to understand.   \n\n                                              Vietnamese  \n0      bạn không nói với tôi bất cứ điều gì tôi không...  \n1      chúng ta cần lấy lại cảm giác khôi hài và vui ...  \n2                              phí vào cửa là bao nhiêu?  \n3             tôi không thể chơi piano cả. tôi là tất cả  \n4      các bạn vừa mới nhìn vào đồng hồ của mình , đú...  \n...                                                  ...  \n19365  khi bạn bắt tay với ai đó, bạn phải nhìn thẳng...  \n19366                             bạn đã sợ, phải không?  \n19367                không biết anh có cưới cô ấy không.  \n19368              tại sao bất cứ ai khác muốn điều này?  \n19369            tất cả điều này là đơn giản và dễ hiểu.  \n\n[19370 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Vietnamese</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>you're not telling me anything i don't know</td>\n      <td>bạn không nói với tôi bất cứ điều gì tôi không...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>we need to get back to that sense of playfulne...</td>\n      <td>chúng ta cần lấy lại cảm giác khôi hài và vui ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>how much is the entrance fee?</td>\n      <td>phí vào cửa là bao nhiêu?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i can't play the piano at all. i'm all thumbs</td>\n      <td>tôi không thể chơi piano cả. tôi là tất cả</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>you just looked at your clock , right ?\\n</td>\n      <td>các bạn vừa mới nhìn vào đồng hồ của mình , đú...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19365</th>\n      <td>when you shake hands with somebody, you must l...</td>\n      <td>khi bạn bắt tay với ai đó, bạn phải nhìn thẳng...</td>\n    </tr>\n    <tr>\n      <th>19366</th>\n      <td>you were scared, right?</td>\n      <td>bạn đã sợ, phải không?</td>\n    </tr>\n    <tr>\n      <th>19367</th>\n      <td>it was uncertain whether he would marry her.</td>\n      <td>không biết anh có cưới cô ấy không.</td>\n    </tr>\n    <tr>\n      <th>19368</th>\n      <td>why would anyone else want this?</td>\n      <td>tại sao bất cứ ai khác muốn điều này?</td>\n    </tr>\n    <tr>\n      <th>19369</th>\n      <td>all this is simple and easy to understand.</td>\n      <td>tất cả điều này là đơn giản và dễ hiểu.</td>\n    </tr>\n  </tbody>\n</table>\n<p>19370 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T09:44:59.980577Z",
     "start_time": "2024-03-22T09:44:59.968921Z"
    }
   },
   "id": "233ee33c6da1a3be",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
